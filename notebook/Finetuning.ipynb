{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.0\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = r\".\\data\\hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "D:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.4638 Acc: 0.7619\n",
      "val Loss: 0.3449 Acc: 0.9175\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.3682 Acc: 0.8166\n",
      "val Loss: 0.2704 Acc: 0.8831\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.3565 Acc: 0.8225\n",
      "val Loss: 0.2229 Acc: 0.8716\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.3436 Acc: 0.8462\n",
      "val Loss: 0.2154 Acc: 0.9739\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.3343 Acc: 0.8462\n",
      "val Loss: 0.2077 Acc: 0.9729\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.3232 Acc: 0.8643\n",
      "val Loss: 0.2041 Acc: 0.8768\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.3186 Acc: 0.8709\n",
      "val Loss: 0.2143 Acc: 0.9624\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.3024 Acc: 0.8677\n",
      "val Loss: 0.1827 Acc: 0.9718\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.2993 Acc: 0.8733\n",
      "val Loss: 0.2380 Acc: 0.9238\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.2950 Acc: 0.8740\n",
      "val Loss: 0.1700 Acc: 0.9760\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.8771\n",
      "val Loss: 0.1641 Acc: 0.9749\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.2935 Acc: 0.8806\n",
      "val Loss: 0.1784 Acc: 0.9729\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.2892 Acc: 0.8778\n",
      "val Loss: 0.1772 Acc: 0.9718\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.2803 Acc: 0.8865\n",
      "val Loss: 0.1955 Acc: 0.9676\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.2883 Acc: 0.8730\n",
      "val Loss: 0.1502 Acc: 0.9760\n",
      "\n",
      "Training complete in 35m 32s\n",
      "Best val Acc: 0.975992\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6903 Acc: 0.5952\n",
      "val Loss: 0.6931 Acc: 0.6065\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.6053\n",
      "val Loss: 0.6789 Acc: 0.6065\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6515 Acc: 0.6070\n",
      "val Loss: 0.6355 Acc: 0.6065\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.6251\n",
      "val Loss: 0.6199 Acc: 0.6065\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6152 Acc: 0.6063\n",
      "val Loss: 0.5935 Acc: 0.6065\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6183 Acc: 0.6063\n",
      "val Loss: 0.6036 Acc: 0.6065\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.5964 Acc: 0.6067\n",
      "val Loss: 0.6028 Acc: 0.6065\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.5988 Acc: 0.6067\n",
      "val Loss: 0.6129 Acc: 0.6065\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.5930 Acc: 0.6063\n",
      "val Loss: 0.5901 Acc: 0.6065\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.5766 Acc: 0.6074\n",
      "val Loss: 0.6048 Acc: 0.6065\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.5776 Acc: 0.6133\n",
      "val Loss: 0.5843 Acc: 0.6065\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.5851 Acc: 0.6210\n",
      "val Loss: 0.5800 Acc: 0.6065\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.5897 Acc: 0.6063\n",
      "val Loss: 0.5849 Acc: 0.6065\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.5720 Acc: 0.6063\n",
      "val Loss: 0.5697 Acc: 0.6065\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.6067\n",
      "val Loss: 0.5698 Acc: 0.6065\n",
      "\n",
      "Training complete in 34m 35s\n",
      "Best val Acc: 0.606472\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4FeX5//H3JyEh7MiisimoKCAgagRciwtWVMDWtoorSLXVilpr+/Vb61rtz6W29mutS8Ud961gtVgUd0FWkUUEESQGWQ1LSMh2//6YOcdDOElOyDk5JNyv6zpXZn3mPpM5c888M/OMzAznnHMOICPdATjnnNt1eFJwzjkX5UnBOedclCcF55xzUZ4UnHPORXlScM45F+VJIQGSuksySU3C/jckXZjItDuxrN9Lergu8bqGr67bURKWf7SkJZK2SDojxcvKDJezTzKnbQgkPSXppnTHEWu3SAqSJku6Jc7wkZK+re0Pz8yGmdnjSYhriKS8SmX/ycx+Xteya1imSfpdqpbRGEkaHa6331YanidpSJrCSqVbgL+bWUszezV2RLhTjnwqJBXF9J9b2wWZWXm4nK+TOW1tSbpVUmml77cu2cvZ1e0WSQF4DDhfkioNPx+YYGZl9R9S2lwIbAj/1qt0HfUm0QbgfyS1TncgtbGT631fYEG8EeFOuaWZtQS+BobHDJuQpOWny4TY72dmHdIdUH3bXZLCq0A74NjIAEl7AKcDT4T9p0maI2mTpJXVndJJekfSz8PuTEl/lrRO0jLgtErTjpG0SNJmScsk/SIc3gJ4A+gcc1TSWdJNkp6KmX+EpAWSCsLl9o4Zt1zSNZLmSdoo6TlJOdXE3Rz4CfAroKek3Erjj5H0UbislZJGh8ObSbpb0opwOR+Ew3Y40wljOinsvknSi+Ep8iZgtKSBkj4Ol7FK0t8lZcfMf7Ck/0raIGl1WJ22t6StktrHTHe4pLWSsiotv3N45NouZtih4f8nS9IBkt4Nv8c6Sc9Vtb7iWAR8DPy6ivX7mKRbY/q3Wz/huvlt+P8qlDRe0l4KqiM3S5oSbpexLpKUH66r38SUlSHpWklfSlov6fnId9b3VU9jJX0NvF1FvBdLWhqu64mSOofDvwT2AyaF22XTWqyjyBH3c5KekbQZOE/SkZKmxfzf/y/yv5PUJIy3e9j/VDg+sl4+ltSjttOG44dJ+iL8f98r6cPIdl3L7xRZ7jhJX4Xbzu2SMsLxGZJuCH8ja8JtoXXM/MeF33+jgt/W+THFt6viu2aE321NON88SX1qG3utmdlu8QH+CTwc0/8LYG5M/xCgH0Gi7A+sBs4Ix3UHDGgS9r8D/Dzs/iXwOdCNIPFMrTTtacD+gIAfAFuBw2KWmVcpzpuAp8LuA4FCYCiQBfwOWApkh+OXA58AncNlLwJ+Wc06OB9YBWQCk4D/ixm3D7AZGBUuqz0wIBx3X/idu4TzHgU0rSL+5cBJMd+lFDgjXK/NgMOBwUCTcL0uAq4Kp28VxvcbICfsHxSOex24NGY5fwXureJ7vg1cHNN/F/BA2P0McF0YTw5wTILbz2jgA2AAUAC0C4fnAUPC7seAWyttU3mV1s00YK9wXa4BZgOHhuvzbeDGStvcM0ALgm1zbcy6vSosq2s474PAM5XmfSKct1mc73MCsA44LJz/XuC9eP/HGtbLDtMBtwIlwPCY//sRwKDw/74f8AVweTh9kzDe7mH/U2FsuQTb4nN8/5uozbR7EmzTI8NxVxNsj6Or+C63Ao9VMS6y3CnAHuE6XhopC7gk/E49CLbbfwGPhuN6hHH8LCynA9//tqqL/zSC33ebcD32AfZO+b4y1QvYVT7AMcDGyA8E+BD4dTXT3wP8tdKPLF5SeJuYHTFwcuy0ccp9Fbgy7B5C9UnheuD5mHEZwDd8vxNaDpwXM/5Owp1fFcueAtwTdo8i2Mlkhf3/C7wSZ54MoAg4JM64ePEvZ/uk8F5V8YTTXBVZbhjTnCqmOwv4MOzOBL4FBlYx7c+Bt8NuASuB48L+J4CHgK613H5GAx+E3c8Dd4TdtU0K58b0vwTcH9M/Dni10jbXq9L/d3zYvQg4MWZcJ4IdXpOYefer5vuMB+6M6W8Zzt+98v+xhvWyw3QEO9e3a5jvGuCFsDvejv6BmGlHAPN3YtqLgPdjxongoGN0FTFFkllBzOe/lZZ7Usz0VwCTw+53gUtixh0MbCP4/Vwf+a5xllld/CcTHHAOAjJqs73W5bO7VB9hZh8Q7ARHStqP4Mjl6ch4SYMkTQ2rJDYSnAEkUp/YmWCnE7EidmR4+jotPEUvAE5NsNxI2dHyzKwiXFaXmGm+jeneSvDj3oGkbsDxQKTO918ER8qR6q5uwJdxZu0QThdvXCJi1w2SDpT0moIL/JuAP/H9+qgqhki8fcL/3VBgo5l9UsW0LwJHhtUhxxH8mN8Px/2OYOfwiYJquYt24jvdAFwqae+dmHd1THdRnP7K/7/K21bnsHtf4JWwOqaAIEmUE5yFxJu3ssrb1hZgPdtvW3VR+f/eS9K/Y/7vt1D97yCh7bqGabf7bVqwp92uujOOp82sbcxnaKXxVf0/tlufYXc20JHqt+sq4zezN4EHgPuB1ZIekNSqhvjrbLdJCqEngAsIqlHeNLPYH+TTwESgm5m1IfhnVL4wHc8qgn96RPRWubAu9iXgz8BeZtaWoBokUq7VUHY+wY8/Up7CZX2TQFyVnU/w/54k6VtgGcHO/oJw/EqCaq7K1gHFVYwrBJrHxJdJ8COIVfk73k9w9NPTzFoDv+f79VFVDJhZMcER+rnhd3ky3nThtAXAmwSn6+cQVKtYOO5bM7vYzDoTVCH+Q9IBVZVVRfmfAy+Hscfabn0AO5M0Kqu8beWH3SuBYZV2YDlmFrttVLd9Vd62WhBUGe7MthVP5WU/CMwHDgj/7zeQ2O+rLlYRVK8B0d9PXZNeVf+P7dZnOK6E4EC0yu26JmZ2j5kdBvQlqD66emfKqY3dMSmcBFwMVL6ltBWwwcyKJQ0k2Jkk4nngCkldw4uE18aMyyaor10LlEkaRnBKGLEaaC+pTTVlnybpxPCi3G8ITkk/SjC2WBcANxPUiUc+Z4bltyc4gzhJ0s/Ci2rtJQ0Iz04eAf6i4CJuZnjRsClBHWqOgov0WcAfwu9bnVbAJmCLpF7ApTHjXgP2lnSVpKaSWkkaFDP+CYJqnBEEp93VeTr8zmey/RnhTyVFdhTfEey8ymsoK56bgTFA25hhc4FTJbULzyKu2olyK7teUnNJB4fLi1wYfwC4TdK+AJI6ShpZi3KfBsZIGhD+L/8ETDez5UmIOZ5WBNW3hQpulvhFipYT6zXgMEnDFdwBdSU7HrTU1u8ktVXwnMQVfP//eAa4WsFF/lbAbQQHIxUE2+opks4Mf1sdJB1S04IU3JQxMIy9kCDJ7My2Wiu7VVIIN/iPCC6+Taw0+jLgFgV3S9xAsENOxD+BycCnBBcNX45Z3maCDed5gh3QObHLDY84nwGWhdUAnWPKxcwWA+cRXARcR3DhbriZlSQYGwCSBhPUM98XHilHPhMJLpaNsuC+71MJEs8Ggh1cZMO9BvgMmBGOu4OgjnMjwXp7mOAIs5CaT8+vCdfDZoJ1F737J1xfQ8Pv+S2whKDKKzL+Q6ACmJ3Azmsi0BNYbWafxgw/ApguaUs4zZVm9lW4nhYowfvsw3meJNiWIp4k2A6WE5yp1ObOpqq8S/A/egv4c1ilAPC3MP43w212GkHdc0LM7C2Cuu6XCI6o9wfOTkK8VfkNwW3QmwnOGpKxbqoV1gScBfyFoGpsf2AOwYFVVc7V9s8pbFHMXW8EN2jMDct5heA6Eny/Lb9PcBa+mSAJRbaV4cD/EPx+ZhPcOFCTtgTXfgoItqlVBDdYpJTCs2rnGgRJbxPU+/pT365WwurNfOAnZvZ+TdNXmrcJwYX4Hik8m9ol7FZnCq5hk3QEwS2UKT/KdI2DpFMktQmryK4Hyghu83RVSFlSkPRI+NDF/CrGK3wwY2n4UMZhqYrFNXySHie4pfaqsJrJuUQcQ1Cdsw44heDZo+qqj3Z7Kas+knQcsAV4wsz6xhl/KsF92acS1IX+zcwSrhN1zjmXfCk7UzCz9wguqlRlJEHCMDObBrSV1ClV8TjnnKtZOhuq6sL2D4LkhcNWVZ5Q0iUEj5HTokWLw3v16lUvATrnXGMxa9asdWZW4y256UwK8R5ciVuXZWYPETRNQG5urs2cOTOVcTnnXKMjaUXNU6X37qM8tn86sCvfPx3onHMuDdKZFCYCF4R3IQ0maMtmh6oj55xz9Sdl1UeSniFoJbKDgjblbyRoGhYze4CgDaBTCZ7W3ErwCL9zrh5sKi5l9cZiJJGZITIlJILujLBbke4404Td2uG9VS7ZyiuMgq0lbCgsoX3LprRrkV3zTHWQsqRgZqNqGG8EL3tx9WTlhq3c/p/P2bqtjAyJjPDHnZEBGeEPP0MKu9l+GhEzfaVpJPZp15wfH9Zlt9tJVFQY320tYe2WbRSVlNO/a1syM3bddbCxqJSH31/GIx98RWFJ3ZvRyQiThKRoEsnMEFmZGWRliiaZYXdGxvfdmaJJRgZZTTLIyoiZJjODJhmKGZ6x3fSZGXy/7UW3Q+Jvt5HtOTJNFdttVmYGzbIzaZ6dSbOszGh3TpNMMlL0f6yoMAqKStlQuI11W4Kd/frCEtZv2RZ0bylhfeH33d9tLaEivNr6px/145xBqX09dUN6TZ6rg7zvtnL2Q9PYWFRKjw4tqDCjvMKoMKPCgg213ML+CnYYX15hVIT95bHTmBF51GXuygJuHnFwyn5M9alwWxlrN29j7ZZtwd/Yz5ZtrNlczNrNwY+6vOL7+yP269iCS3+wP2cc2oWszF2nwYCtJWU8/tEKHnj3SzYWlXJav078sO/eYRv6wf+3PGxPv7yCmO7gYxYM+347INwOYreJcN6KCkrKjbLyCsoqjJLyiqC7PNJtlFVUsLWoPDq8tLyC0oqY7nD+0nKjtKKCdLTGk5OVQfPsJtsli+27m9AsO/40xWUVbNhSEuz4C0vYELOj31D4/U6+sjbNsmjfIpv2LbPp0aEFh+/bjg4ts2nXIpv2LZtyaLe28WdMIk8Ku4FVG4s455/T2VRcyjMXD6Zf16oaZd05FRXGHf/5nAffW0ZRaTl3nNl/lz5a/nr9Vpas2bzdTr5y99Y4R9GZGaJDy2w6tmpKx5ZN6dOpdbS7Y6scikvLefiDr/jti/O4Z8oSfvmD/fhpbjdysjLT8C0D28rKefaTldz79lLWbdnG8Qd15DcnH0TfLsndBlItkpwqwgOX8or4BzPbJarINLEHOJFpwulKyisoLi1na0nw2bG7bIfhGwpLyPuunKKScorCaYpLK+LG3TqnCR3CKp/u7YOdfPsWkZ18Nu1bNA3/ZrNHi+xd4kCiwTWI57ek1s6aTcWc9dA01m7exlM/H8SAFB1pmBl/e2sJ90xZwun9O/HXswbsEht4ZU9NW8GNExdsd3TftnlWuGNvGrOTr/Rp2ZQ9mmfXeBZkZkxdvIa/v72U2V8X0LFVUy4+tgfnDtqXFk3r7xisrLyCl+d8w9+mLOGbgiIG9mjH7354ELnd29U8s6u1igqjuCxIGkUl5WQ3yWCP5tlkN9l1fgOSZplZbo3TeVJovNZu3sbZD33Mqo3FPDl2IIfvm/odwgPvfsntb3zO0D578fdzDqVpk/QdJccqrzBuf2MR/3z/K44/qCNXnnQge7YKjtJSEaOZ8fGy9dw3dSkfLl1P2+ZZjDmqB6OP6k6b5llJX15ERYXxxvxvufu/i1m2tpD+XdtwzckHcWzPDrvd9R63PU8Ku7kNhSWMemgaKzYU8viYgQzar33NMyXJ4x8t58aJCzjuwI48eN7hNMtOb2LYWlLGVc/O5c2Fqxl9VHf+cFpvmtTjWcycr7/jvqlLmbJoDS2bNuG8wfsy9pgedGxV0/uIEmdmvLN4LXdNXszCVZvouWdLfnPyQfzw4L08GTjAk8JurWBrCaP+OZ1la7fw6OgjOOqARF8JnTzPzfiaa1/+jEE92vHwhUfQsh6rTmKt2VTM2MdnsiB/I9ef3ocxR/dISxwAi1Zt4r6pS/n3Z6vIzszg7CO6cckP9qdL22Z1KnfasvXcNXkxs1Z8xz7tmvProT0ZcUiXXfq6jqt/nhR2UxuLSjnv4eks/nYzD1+Yy3EH1vXtgzvvX3O/4ernP+WQrm14dMxA2jRLXbVJPItWbWLsYzMoKCrl3lGHcmLvvWqeqR4sW7uF+9/5klfmfIMEPzq0C5cOOYAeHVrUPHOMeXkF3DV5Me8vWcderZsy7oSe/Cy32y5Vj+12HZ4UdkObi0s5f/wnLMjfyIPnH84JvdK/E/zP/FWMe2YOB+3diicuGpTyB28i3lm8hsufnkOLppmMv/CIXfJum28Kinjo3S95dsZKSssrOK1/Z351/P702rt1tfN9sXozd7+5mMkLVrNH8ywuG3IA5x+5b1rvcnK7Pk8Ku5nCbWVc+MgnzF1ZwD/OPYyTD9473SFFTf18Db98ahbd27fgyZ8PZM9WOSld3pPTVnDjv+bTa+/WPDL6CPZuk9rl1dWazcWM/+Arnvp4BYUl5ZzUey8uP+GAHe4UW7G+kHumLOHVud/QIrsJFx+7Hxcd051WOfV7BuYaJk8Ku5GiknJGP/oJM1d8x72jDuXUfrveayk+WrqOsY/PpFObHCZcPIhObepWjx5PeYXxp9cXMf6Drzix157836hD6/U20Loq2FrCYx8t59EPl7OxqJRjDujAr44PqpXufXsJz81YSZNMceFR3fnlcfuzRz2ddbnGwZPCbqK4tJyxj8/g4y/X89ezBjByQJd0h1Slmcs3MObRGbRpnsUzFw+mW7vmSSu7cFsZVz47lymLgjuMrj+9T4O90LplWxkTpq3gn+9/xbot28JmHODsI/bh8hMOYK/Wu/aZj9s1eVKoZEH+RqYv28Bp/Ts1mh9VcWk5lzw5i/eXrOXPPzmEMw/vmu6QajQvr4Dzx39Cs6xMJlw8iP07tqxzmas3FXPRYzNYtGoTNw4/mAuP6l73QHcBxaXlvDBzJV9v2MoFR3ZPahJ1ux9PCpXcN3Upd01ejASDerRjxCFdGNZ37wZ7Cl5SVsGlT83irc/XcOeZ/fnZEd1qnmkXsWjVJs4fPx2Ap34+qMYLq9VZmL+JsY/PYFNRKfeec+gucXHduV2RJ4U4lq7Zwmvz8pn4aT7L1hbSJEMc07MDw/t35uSD92owF+xKyyu4/OnZTF6wmtt+1JdzB+2b7pBqbemaLZz78DS2lVXw5EWDdqo9pqmfr+Hyp2fTKieLR0YfQZ/OO59cnGvsPClUw8xYuGoTkz5dxaRP8/mmoIjsJhmccNCeDD+kMyf02jPtT+FWpay8giufm8u/563ipuF9GJ3Gh7HqasX6wqChvqJSHrvoiFo1w/H4R8u5edICendqzfgLd/07jJxLN08KCTIz5qwsYOLcfP792SrWbt5G8+xMhvbZixGHdObYnh13mYeByiuM3zw/l1fn5vOH03rz82P3S3dIdZZfUMS5D09n9aZiHr4wl6P2r/7p6/IK44+vLeSxj5ZzUu+9+NvZAxrUHUbOpYsnhZ1QXmFM/2o9kz5dxRvzV1GwtZTWOU0Y1rcTww/pzJH7t0/bHS0VFcbvXprHi7Py+N0pB3HZkAPSEkcqrNlczHkPT2fF+q08eP7hDDloz7jTFW4r44pn5vDW52sYe0wPfn9q7wZ7h5Fz9c2TQh2VllfwwdJ1TJqbz5sLV7NlWxkdWjbltH57M/yQzhy2zx719jKZigrj9698xrMzVnL10AO54sSe9bLc+rShsITzx0/ni9WbuXfUYZzSd/uH777dWMzYx4M7jG4e2ZfzBze86yjOpZMnhSQqLi3nncVrmPTpKqYsWs22sgq6tG3G6f2DM4iDO7dOWUuUZsYN/1rAk9NWMO6EA/jNyQelZDm7go1FpYx+9BPm5W3kLz87JPrMxYL8jYx9bCabi0v5+7mHcXwVZxLOuap5UkiRLdvKmLJwNZM+zee9JWspLTfaNs+ic5tmdG7bjM5tc+jcthmd2uSE/c3Yq1XTnWqq2cy45bWFPPrhcn7xg/249pRejb4Z5C3byhj72Aw+Wb6BO37cn/Ytsxn3zBzaNsti/Ogj6N3J7zBybmd4UqgHBVtLmLzgW+blbWTVxmLyC4rILyhiU3HZdtNlCPZqnUOnNjl0atuMLrFJo00zOrXNoX2L7O12+GbG7W8Er7gce0wP/nBa70afECKKSsq55MmZvL9kHRmCgzu3YfyFuezZSB46dC4dPCmk0ZZtZawqKCI/TBSrCor4pqCYVRuLWLWxmG8Kiigp2/6drk2bZEQTRac2zSgpr2DSp/lccOS+3Dzi4N0mIURsKyvnf1/6DANu+1Ffmmf7HUbO1YUnhV2YmbGhsIT8gmLyNxZtl0DyC4LEsW7LNs4ZuA83Dj+43i5oO+car0STgh9+pYEk2rdsSvuWTat8ktfMdruzA+dc+u0aT2W5HXhCcM6lgycF55xzUZ4UnHPORXlScM45F+VJwTnnXJQnBeecc1GeFJxzzkV5UnDOORflScE551yUJwXnnHNRnhScc85FpTQpSDpF0mJJSyVdG2f8PpKmSpojaZ6kU1MZj3POueqlLClIygTuA4YBfYBRkvpUmuwPwPNmdihwNvCPVMXjnHOuZqk8UxgILDWzZWZWAjwLjKw0jQGRV2m1AfJTGI9zzrkapDIpdAFWxvTnhcNi3QScJykPeB0YF68gSZdImilp5tq1a1MRq3POOVKbFOK1/Vz5jT6jgMfMrCtwKvCkpB1iMrOHzCzXzHI7duyYglCdc85BapNCHtAtpr8rO1YPjQWeBzCzj4EcoEMKY3LOOVeNVCaFGUBPST0kZRNcSJ5YaZqvgRMBJPUmSApeP+Scc2mSsqRgZmXA5cBkYBHBXUYLJN0iaUQ42W+AiyV9CjwDjLaG9tJo55xrRFL6jmYze53gAnLssBtiuhcCR6cyBuecc4nzJ5qdc85FeVJwzjkX5UnBOedclCcF55xzUZ4UnHPORXlScM45F+VJwTnnXJQnBeecc1GeFJxzzkV5UnDOORflScE551xUjUkhfK2mc8653UAiZwpLJd0V5/3KzjnnGplEkkJ/4AvgYUnTwldjtq5pJueccw1PjUnBzDab2T/N7Cjgd8CNwCpJj0s6IOUROuecqzcJXVOQNELSK8DfgLuB/YBJVHpXgnPOuYYtkZfsLAGmAneZ2Ucxw1+UdFxqwnLOOZcOiSSF/ma2Jd4IM7siyfE455xLo0QuNN8nqW2kR9Iekh5JYUzOOefSJKG7j8ysINJjZt8Bh6YuJOecc+mSSFLIkLRHpEdSOxKrdnLOOdfAJLJzvxv4SNKLYf9PgdtSF5Jzzrl0qTEpmNkTkmYBxwMCfmxmC1MemXPOuXqXUDWQmS2QtBbIAZC0j5l9ndLInHPO1btEHl4bIWkJ8BXwLrAceCPFcTnnnEuDRC40/xEYDHxhZj2AE4EPUxqVc865tEgkKZSa2XqCu5AyzGwqMCDFcTnnnEuDRK4pFEhqCbwHTJC0BihLbVjOOefSIZEzhZHAVuDXwH+AL4HhqQzKOedcelR7phC+de1fZnYSUAE8Xi9ROeecS4tqzxTMrBzYKqlNPcXjnHMujRK5plAMfCbpv0BhZKC3kOqcc41PIknh3+HHOedcI5dIMxd+HcE553YTiTzR/JWkZZU/iRQu6RRJiyUtlXRtFdP8TNJCSQskPV3bL+Cccy55Eqk+yo3pziFoJbVdTTOFdy7dBwwF8oAZkibGNqYnqSfwv8DRZvadpD1rE3ytvHEtfPtZyop3zrmU27sfDLs9pYuo8UzBzNbHfL4xs3uAExIoeyCw1MyWmVkJ8CzBMw+xLgbuC1/cg5mtqWX8zjnnkqjGMwVJh8X0ZhCcObRKoOwuwMqY/jxgUKVpDgyX8SGQCdxkZv+JE8MlwCUA++yzTwKLjiPF2dU55xqDRF+yE1FG0FrqzxKYT3GGWZzl9wSGAF2B9yX1jX39J4CZPQQ8BJCbm1u5DOecc0mSyN1Hx+9k2XlAt5j+rkB+nGmmmVkp8JWkxQRJYsZOLtM551wdJHL30Z8ktY3p30PSrQmUPQPoKamHpGzgbGBipWleJXijG5I6EFQnJXRnk3POueRLpEG8YbHVOeFF4VNrmsnMyoDLgcnAIuD58A1ut0gaEU42GVgvaSEwFfht2Ey3c865NEjkmkKmpKZmtg1AUjOgaSKFm9nrwOuVht0Q023A1eHHOedcmiWSFJ4C3pL0KMGF4ovw1lKdc65RSuRC852S5gEnEdxR9Eczm5zyyJxzztW7RJ5T6AG8E3l+QFIzSd3NbHmqg3POOVe/ErnQ/ALBC3YiysNhzjnnGplEkkKTsJkKAMLu7NSF5JxzLl0SSQprY24hRdJIYF3qQnLOOZcuidx99EtggqS/E1xoXglckNKonHPOpUUidx99CQyW1BKQmW2WtFfqQ3POOVffEqk+isgEfippCjA7RfE455xLo2rPFMKnl0cA5wCHETSZfQbwXupDc845V9+qPFOQNAH4AjgZ+DvQHfjOzN4xs4qq5nPOOddwVVd91Bf4jqAxu8/NrJwd34fgnHOuEakyKZjZIQQv02kNTJH0PtBK0t71FZxzzrn6Ve2FZjP73MxuMLODgF8DTwCfSPqoXqJzzjlXrxJ5TgEAM5sJzJR0DXBc6kJyzjmXLgknhYjwHQjvpiAW55xzaVab5xScc841cp4UnHPORSXyPoWmwJkEzylEpzezW1IXlnPOuXRI5JrCv4CNwCxgW2rDcc45l06JJIWuZnZKyiNxzjmXdolcU/hIUr+UR+Kccy7tEjlTOAYYLekrguojEdyZ2j+lkTnnnKt3iSSFYSmPwjnn3C6hxuojM1sBtAWGh5+24TDnnHONTI1JQdKVwARgz/DzlKRxqQ7MOedc/Uuk+mgsMMjMCgEk3QF8DNybysCcc87Vv0TuPhJQHtNfHg5zzjnXyCRypvAoMF3SK2H/GcD41IXknHNWy4SRAAAWmElEQVQuXWpMCmb2F0nvENyaKmCMmc1JdWDOOefqX5VJQVJrM9skqR2wPPxExrUzsw2pD88551x9qu5M4WngdII2j2Lfzaywf78UxuWccy4NqkwKZnZ6+LdH/YXjnHMunRJ5TuGtRIY555xr+Kq7ppADNAc6SNqD729DbQ10rofYnHPO1bPqzhR+QXA9oVf4N/L5F3BfIoVLOkXSYklLJV1bzXQ/kWSSchMP3TnnXLJVd03hb8DfJI0zs1o/vSwpkyB5DAXygBmSJprZwkrTtQKuAKbXdhnOOeeSK5HnFO6V1BfoA+TEDH+ihlkHAkvNbBmApGeBkcDCStP9EbgTuKYWcTvnnEuBRC4030jQztG9wPEEO/ARCZTdBVgZ058XDost+1Cgm5m9VkMMl0iaKWnm2rVrE1i0c865nZFI20c/AU4EvjWzMcAhQNME5ovXPlL0eQdJGcBfgd/UVJCZPWRmuWaW27FjxwQW7ZxzbmckkhSKzKwCKJPUGlhDYg+u5QHdYvq7Avkx/a2AvsA7kpYDg4GJfrHZOefSJ5EG8WZKagv8k+Duoy3AJwnMNwPoKakH8A1wNnBOZKSZbQQ6RPrD9pWuMbOZCUfvnHMuqRK50HxZ2PmApP8Arc1sXgLzlUm6HJgMZAKPmNkCSbcAM81sYl0Cd845l3zVPbx2WHXjzGx2TYWb2evA65WG3VDFtENqKs8551xqVXemcHf4NwfIBT4luHjcn+CZgmNSG5pzzrn6VuWFZjM73syOB1YAh4V3/xwOHAosra8AnXPO1Z9E7j7qZWafRXrMbD4wIHUhOeecS5dE7j5aJOlh4CmC5wzOAxalNCrnnHNpkUhSGANcClwZ9r8H3J+yiJxzzqVNIrekFhM8efzX1IfjnHMunaq7JfV5M/uZpM/Y/nWcAJhZ/5RG5pxzrt5Vd6YQqS46vT4Ccc45l37VvU9hVfh3Rf2F45xzLp2qqz7aTJxqI4IH2MzMWqcsKuecc2lR3ZlCq/oMxDnnXPolcksqAJL2ZPs3r32dkoicc86lTSJvXhshaQnwFfAusBx4I8VxOeecS4NEmrn4I8ELcL4wsx4Eb2H7MKVROeecS4tEkkKpma0HMiRlmNlUvO0j55xrlBK5plAgqSVB8xYTJK0BylIblnPOuXRI5ExhJFAE/Br4D/AlMDyVQTnnnEuP6p5T+DvwtJl9FDP48dSH5JxzLl2qO1NYAtwtabmkOyT5dQTnnGvkqnvz2t/M7EjgB8AG4FFJiyTdIOnAeovQOedcvanxmoKZrTCzO8zsUOAc4Ef4S3acc65RSuThtSxJwyVNIHho7QvgzJRH5pxzrt5Vd6F5KDAKOA34BHgWuMTMCuspNuecc/WsuucUfg88DVxjZhvqKR7nnHNpVF0rqcfXZyDOOefSL5GH15xzzu0mPCk455yL8qTgnHMuypOCc865KE8KzjnnojwpOOeci/Kk4JxzLsqTgnPOuShPCs4556JSmhQknSJpsaSlkq6NM/5qSQslzZP0lqR9UxmPc8656qUsKUjKBO4DhgF9gFGS+lSabA6Qa2b9gReBO1MVj3POuZql8kxhILDUzJaZWQlBK6sjYycws6lmtjXsnQZ0TWE8zjnnapDKpNAFWBnTnxcOq8pYgvc17EDSJZJmSpq5du3aJIbonHMuViqTguIMs7gTSucBucBd8cab2UNmlmtmuR07dkxiiM4552JV9z6FusoDusX0dwXyK08k6STgOuAHZrYthfE455yrQSrPFGYAPSX1kJQNnA1MjJ1A0qHAg8AIM1uTwlicc84lIGVJwczKgMuBycAi4HkzWyDpFkkjwsnuAloCL0iaK2liFcU555yrB6msPsLMXgderzTshpjuk1K5fOecc7WT0qRQX0pLS8nLy6O4uDjdoTQ6OTk5dO3alaysrHSH4pyrB40iKeTl5dGqVSu6d++OFO+mJ7czzIz169eTl5dHjx490h2Oc64eNIq2j4qLi2nfvr0nhCSTRPv27f0MzLndSKNICoAnhBTx9erc7qXRJAXnnHN150khSTIzMxkwYAB9+/blpz/9KVu3bq15phj33HNPrecBuOGGG5gyZUqt54tnyJAhzJw5MyllOecaJk8KSdKsWTPmzp3L/Pnzyc7O5oEHHthuvJlRUVFR5fzVJYXy8vIq57vllls46SS/s9c5lxyN4u6jWDdPWsDC/E1JLbNP59bcOPzghKc/9thjmTdvHsuXL2fYsGEcf/zxfPzxx7z66qssXryYG2+8kW3btrH//vvz6KOP8sgjj5Cfn8/xxx9Phw4dmDp1Ki1btuTqq69m8uTJ3H333bz99ttMmjSJoqIijjrqKB588EEkMXr0aE4//XR+8pOf0L17dy688EImTZpEaWkpL7zwAr169aKwsJBx48bx2WefUVZWxk033cTIkSMpKipizJgxLFy4kN69e1NUVJTU9eaca3j8TCHJysrKeOONN+jXrx8Aixcv5oILLmDOnDm0aNGCW2+9lSlTpjB79mxyc3P5y1/+whVXXEHnzp2ZOnUqU6dOBaCwsJC+ffsyffp0jjnmGC6//HJmzJjB/PnzKSoq4rXXXou7/A4dOjB79mwuvfRS/vznPwNw2223ccIJJzBjxgymTp3Kb3/7WwoLC7n//vtp3rw58+bN47rrrmPWrFn1s5Kcc7usRnemUJsj+mQqKipiwIABQHCmMHbsWPLz89l3330ZPHgwANOmTWPhwoUcffTRAJSUlHDkkUfGLS8zM5Mzzzwz2j916lTuvPNOtm7dyoYNGzj44IMZPnz4DvP9+Mc/BuDwww/n5ZdfBuDNN99k4sSJ0SRRXFzM119/zXvvvccVV1wBQP/+/enfv38yVoVzrgFrdEkhXSLXFCpr0aJFtNvMGDp0KM8880yN5eXk5JCZmQkEO/HLLruMmTNn0q1bN2666aYqnx1o2rQpECSVsrKy6HJfeuklDjrooB2m91tOnXOxvPqoHg0ePJgPP/yQpUuXArB161a++OILAFq1asXmzZvjzhdJAB06dGDLli28+OKLtVruD3/4Q+69917MgtdZzJkzB4DjjjuOCRMmADB//nzmzZtX+y/lnGtUPCnUo44dO/LYY48xatQo+vfvz+DBg/n8888BuOSSS6IXpStr27YtF198Mf369eOMM87giCOOqNVyr7/+ekpLS+nfvz99+/bl+uuvB+DSSy9ly5Yt9O/fnzvvvJOBAwfW/Us65xo0RY4eG4rc3FyrfC/9okWL6N27d5oiavx8/TrX8EmaZWa5NU3nZwrOOeeiPCk455yL8qTgnHMuypOCc865KE8KzjnnojwpOOeci/KkkES33XYbBx98MP3792fAgAFMnz69TuUVFBTwj3/8o8bpvMlr51yyeFJIko8//pjXXnuN2bNnM2/ePKZMmUK3bt1qnC/SFEU8iSYF55xLlsbX9tEb18K3nyW3zL37wbDbq51k1apVdOjQIdr2UIcOHQCYMWMGV155JYWFhTRt2pS33nqLl156iX//+98UFxdTWFjIxIkTGTlyJN999x2lpaXceuutjBw5kmuvvZYvv/ySAQMGMHToUO666y7uvPNOnnzySTIyMhg2bBi33x7E9cILL3DZZZdRUFDA+PHjOfbYY5O7Dpxzu4XGlxTS5OSTT+aWW27hwAMP5KSTTuKss87iyCOP5KyzzuK5557jiCOOYNOmTTRr1gwIzizmzZtHu3btKCsr45VXXqF169asW7eOwYMHM2LECG6//Xbmz58fbWjvjTfe4NVXX2X69Ok0b96cDRs2RJdfVlbGJ598wuuvv87NN9+ctLexOed2L40vKdRwRJ8qLVu2ZNasWbz//vtMnTqVs846i+uuu45OnTpF2ypq3bp1dPqhQ4fSrl07IGjF9Pe//z3vvfceGRkZfPPNN6xevXqHZUyZMoUxY8bQvHlzgOj8sH2T2cuXL0/V13TONXKNLymkUWZmJkOGDGHIkCH069eP++67r8qmqWOb1J4wYQJr165l1qxZZGVl0b1797hNY5tZleXFazLbOedqyy80J8nixYtZsmRJtH/u3Ln07t2b/Px8ZsyYAcDmzZvj7rA3btzInnvuSVZWFlOnTmXFihXAjs1pn3zyyTzyyCPRdznHVh8551wy+JlCkmzZsoVx48ZRUFBAkyZNOOCAA3jooYcYM2YM48aNo6ioiGbNmsWt6z/33HMZPnw4ubm5DBgwgF69egHQvn17jj76aPr27cuwYcO46667mDt3Lrm5uWRnZ3Pqqafypz/9qb6/qnOuEfOms12NfP061/B509nOOedqzZOCc865qEaTFBpaNVhD4evVud1Lo0gKOTk5rF+/3ndgSWZmrF+/npycnHSH4pyrJ43i7qOuXbuSl5fH2rVr0x1Ko5OTk0PXrl3THYZzrp40iqSQlZVFjx490h2Gc841eCmtPpJ0iqTFkpZKujbO+KaSngvHT5fUPZXxOOecq17KkoKkTOA+YBjQBxglqU+lycYC35nZAcBfgTtSFY9zzrmapfJMYSCw1MyWmVkJ8CwwstI0I4HHw+4XgRNVVeM+zjnnUi6V1xS6ACtj+vOAQVVNY2ZlkjYC7YF1sRNJugS4JOzdImnxTsbUoXLZSeLlNqxYU1VuQ4q1oZXbkGLdVcvdN5GJUpkU4h3xV75nNJFpMLOHgIfqHJA0M5HHvL3cXaPMhlZuQ4q1oZXbkGJtiOXGSmX1UR4Q+z7KrkB+VdNIagK0AbzpT+ecS5NUJoUZQE9JPSRlA2cDEytNMxG4MOz+CfC2+RNozjmXNimrPgqvEVwOTAYygUfMbIGkW4CZZjYRGA88KWkpwRnC2amKJ1TnKigvt17LbGjlNqRYG1q5DSnWhlhuVINrOts551zqNIq2j5xzziWHJwXnnHNRu0VSkPSIpDWS5ie53G6SpkpaJGmBpCuTUGaOpE8kfRqWeXMyYo0pP1PSHEmvJbHM5ZI+kzRX0sya50i43LaSXpT0ebiOj6xjeQeFMUY+myRdlaRYfx3+v+ZLekZSUpqWlXRlWOaCusQa7zcgqZ2k/0paEv7dIwll/jSMtULSTt06WUW5d4XbwTxJr0hqm6Ry/xiWOVfSm5I6J6PcmHHXSDJJHZIQ602SvonZfk+tbawJMbNG/wGOAw4D5ie53E7AYWF3K+ALoE8dyxTQMuzOAqYDg5MY89XA08BrSSxzOdAhBf+3x4Gfh93ZQNsklp0JfAvsm4SyugBfAc3C/ueB0Ukoty8wH2hOcFPIFKDnTpa1w28AuBO4Nuy+FrgjCWX2Bg4C3gFykxjryUCTsPuO2sZaTbmtY7qvAB5IRrnh8G4EN9qsqO3vo4pYbwKuqet2VdNntzhTMLP3SMHzD2a2ysxmh92bgUUEO4i6lGlmtiXszQo/SbkbQFJX4DTg4WSUl0qSWhP8MMYDmFmJmRUkcREnAl+a2YokldcEaBY+b9OcHZ/J2Rm9gWlmttXMyoB3gR/tTEFV/AZim5l5HDijrmWa2SIz29kWB6or981wHQBMI3juKRnlborpbcFO/Naq2b/8FfhdkstMud0iKdSHsIXXQwmO7OtaVqakucAa4L9mVucyQ/cQbKQVSSovwoA3Jc0KmyRJhv2AtcCjYXXXw5JaJKlsCG5/fiYZBZnZN8Cfga+BVcBGM3szCUXPB46T1F5Sc+BUtn8gtK72MrNVEBzgAHsmsexUugh4I1mFSbpN0krgXOCGJJU5AvjGzD5NRnkxLg+rux6pbXVfojwpJIGklsBLwFWVjjx2ipmVm9kAgqOhgZL6JiHG04E1ZjarrmXFcbSZHUbQIu6vJB2XhDKbEJw+329mhwKFBFUcdRY+TDkCeCFJ5e1BcNTdA+gMtJB0Xl3LNbNFBFUl/wX+A3wKlFU7UyMn6TqCdTAhWWWa2XVm1i0s8/K6lhcm8OtIUoKJcT+wPzCA4ODj7iSXD3hSqDNJWQQJYYKZvZzMssPqkneAU5JQ3NHACEnLCVqsPUHSU0koFzPLD/+uAV4haCG3rvKAvJizpBcJkkQyDANmm9nqJJV3EvCVma01s1LgZeCoZBRsZuPN7DAzO46gOmFJMsoNrZbUCSD8uyaJZSedpAuB04FzLaxkT7KngTOTUM7+BAcIn4a/t67AbEl716VQM1sdHjBWAP8kOb+zHXhSqANJIqjzXmRmf0lSmR0jd1ZIakaww/m8ruWa2f+aWVcz605QdfK2mdX5aFZSC0mtIt0EFwTrfJeXmX0LrJR0UDjoRGBhXcsNjSJJVUehr4HBkpqH28SJBNeX6kzSnuHffYAfk9y4Y5uZuRD4VxLLTipJpwD/A4wws61JLLdnTO8IkvNb+8zM9jSz7uHvLY/ghpRv61JuJIGHfkQSfmdxpfpK9q7wIfghrQJKCf5BY5NU7jEE9enzgLnh59Q6ltkfmBOWOR+4IQXrYwhJuvuIoO7/0/CzALguiXEOAGaG6+JVYI8klNkcWA+0SfI6vZlghzIfeBJomqRy3ydIhp8CJ9ahnB1+AwTN1L9FcPbxFtAuCWX+KOzeBqwGJicp1qUEzexHfmc7c5dQvHJfCv9n84BJQJdklFtp/HJqf/dRvFifBD4LY50IdErmNhz5eDMXzjnnorz6yDnnXJQnBeecc1GeFJxzzkV5UnDOORflScE551yUJwXXYITNPURaiPy2UouR2QmW8WjMsw9VTfMrSecmKeYPJC2OifO5ZJQbU37ezrQY6lxV/JZU1yBJugnYYmZ/rjRcBNt1stt32imSPgAuN7O5KSo/D+hryW0s0O3G/EzBNXiSDgjfOfAAMBvoJOkhSTPDtv1viJn2A0kDJDWRVCDpdgXvrvg45unhWxW+uyCc/nYF77hYLOmocHgLSS+F8z4TLmtALWJ+StL9kt6X9IWkYeHwZpIeV/B+itmRdqTCeP8afs95ki6LKe6qsNHAeZIODKc/IYxtblhOMhsTdI2YJwXXWPQBxpvZoRa0WnqtmeUChwBDJfWJM08b4F0zOwT4mKD1zXhkZgOB3/J9I2fjgG/DeW8naCG3Ks/FVB/dHjO8G/ADYDjwkKSmBG36l5hZP+B84MmwauxSgsb2DjGz/gTtV0WstqDRwIcJ3pdBGOslFjSseBxQXE18zkV5UnCNxZdmNiOmf5Sk2QRnDr0JkkZlRWYWaYJ5FtC9irJfjjPNMYQ7ZguaR15QTWxnmdmA8BPb0uvzZlZhwfsHVgI9w3KfDMtdQPBehgMI2sB6wMzKw3Gxbe3Hi+9D4B5J4wheJFNeTXzORXlScI1FYaQjbOTsSuCE8Kj6P0C812OWxHSXEzTXHc+2ONOoTtEGKl/Qs2rKVZzpI3aIz8xuBX4BtARmVGr4zbkqeVJwjVFrYDOwKWxZ8ocpWMYHwM8AJPUj/plITX6qwIEEVUlLgPcIXvaCpN4Er3xdCrwJXCopMxzXrrqCJe1vZvPM7P8RNLBY7R1XzkVUdWTkXEM2m6Bl0fnAMoKqlGS7F3hC0rxwefOBjVVM+5ykorB7tZlFktRSgiSwJ0H9f4mke4EHJX1G0ELmBeHwBwmql+ZJKiN44coD1cR3jaRjCd6yN48gqThXI78l1bmdoOBdzE3MrDismnkT6Gnfv0e4pvmfAl40s1dTGadzteVnCs7tnJbAW2FyEPCLRBOCc7syP1NwzjkX5ReanXPORXlScM45F+VJwTnnXJQnBeecc1GeFJxzzkX9fx7o4bdsCUD5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
